{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Подготовка золотого стандарта.  \n",
        "Я использовала тегсет UDpipe, потому что он довольно полный, при этом универсальный (без большого количества подробностей) и интуитивно понятный. Однако я внесла некоторые упрощения - объединила SCONJ и CCONJ под единым тэгом CONJ; DET - под тэгом ADJ, так как далеко не все тэггеры учитывают различие в союзах.\n",
        "Текст для разметки я составляла из предложений с феминитивами, окказионализмами, заимствованиями, омонимами, так как все это представляет сложность для автоматического тэггинга. В случае с первыми тремя - данные слова могут быть незнакомы словарю, а в случае с омонимами - не все тэггеры могут различать омонимию, так как для этого нужно учитывать контекст. "
      ],
      "metadata": {
        "id": "7iJNckfS30cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "oC1Gcomez3cF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('analysis.conllu', 'r', encoding='utf-8') as f:\n",
        "  file = f.readlines()"
      ],
      "metadata": {
        "id": "rF_o3cCFu_3k"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(file)):\n",
        "  file[i] = file[i].split('\\t')\n",
        "  file[i] = file[i][1:4:2]"
      ],
      "metadata": {
        "id": "r7GuU_SxvOKJ"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('golden.tsv','w') as file_out:\n",
        "  file_out.write('form\\ttag\\n')\n",
        "with open('golden.tsv','a') as file_out:\n",
        "    for line in file:\n",
        "        if len(line) != 0:\n",
        "          string = f'{line[0]}\\t{line[1]}'\n",
        "          file_out.write(string)\n",
        "          file_out.write('\\n')"
      ],
      "metadata": {
        "id": "mwOMR30_wFRb"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('golden.tsv', delimiter='\\t')"
      ],
      "metadata": {
        "id": "NJ0ZIhafwJhR"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "37cKNDJI2wet",
        "outputId": "6bf5ad53-355e-487e-874e-d593cdf92a07"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            form   tag\n",
              "0          Тогда   ADV\n",
              "1             бы   AUX\n",
              "2          узрел  VERB\n",
              "3    легендарную   ADJ\n",
              "4           щуку  NOUN\n",
              "..           ...   ...\n",
              "258       работе  NOUN\n",
              "259         видя  VERB\n",
              "260   прекрасные   ADJ\n",
              "261        ножки  NOUN\n",
              "262      девушек  NOUN\n",
              "\n",
              "[263 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1473fa7-036c-45bf-bfcb-176cae84d34b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>form</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Тогда</td>\n",
              "      <td>ADV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бы</td>\n",
              "      <td>AUX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>узрел</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>легендарную</td>\n",
              "      <td>ADJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>щуку</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>работе</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>видя</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>прекрасные</td>\n",
              "      <td>ADJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>ножки</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>девушек</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>263 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1473fa7-036c-45bf-bfcb-176cae84d34b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1473fa7-036c-45bf-bfcb-176cae84d34b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1473fa7-036c-45bf-bfcb-176cae84d34b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Тэггеры.  \n",
        "Я буду использовать следующие тэггеры: Natasha, Pymorhy и Spacy.   "
      ],
      "metadata": {
        "id": "ewZ8B4gJ4Sc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "4p6EQKRl9F9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "id": "FePWXax39d8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "hkCkfMGH8fQ5"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\")"
      ],
      "metadata": {
        "id": "OgjQIs109MM6"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('trial.txt', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "analized = nlp(text)"
      ],
      "metadata": {
        "id": "D8YBi5As9qUs"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('spacy.tsv', 'w', encoding='utf-8') as f:\n",
        "  f.write(f'form\\ttag\\n')\n",
        "  for token in analized:\n",
        "    f.write(f'{token}\\t{token.pos_}\\n')"
      ],
      "metadata": {
        "id": "DpK1Ge-X94PN"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pymorphy**"
      ],
      "metadata": {
        "id": "R_sbOMX7AARY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "bp9eed8KqTYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD_Ol0_U-D-l",
        "outputId": "dd67aa31-b69d-4ad4-dbb9-52ef7c59949f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_toks = word_tokenize(text)"
      ],
      "metadata": {
        "id": "VHJpf4SYAbJj"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "with open('pymorphy.tsv', 'w', encoding='utf-8') as f:\n",
        "  f.write('form\\ttag\\n')\n",
        "  for i in text_toks:\n",
        "    if i != '':\n",
        "      f.write(f'{i}\\t{morph.parse(i)[0].tag.POS}\\n')"
      ],
      "metadata": {
        "id": "LxZmyO52rCYY"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "3U7MIgmxxr4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "    DatesExtractor,\n",
        "    MoneyExtractor,\n",
        "    AddrExtractor,\n",
        "\n",
        "    Doc\n",
        ")"
      ],
      "metadata": {
        "id": "doHFlA2XrzXr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "\n",
        "names_extractor = NamesExtractor(morph_vocab)\n",
        "dates_extractor = DatesExtractor(morph_vocab)\n",
        "money_extractor = MoneyExtractor(morph_vocab)\n",
        "addr_extractor = AddrExtractor(morph_vocab)"
      ],
      "metadata": {
        "id": "p8As5T2jBuUQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('trial.txt', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "wLrhw_Crx0p8"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = Doc(text)\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNAaec4pBUSJ",
        "outputId": "1d127da8-6a28-4ffa-bf83-fbe0391a8965"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Doc(text='Тогда бы узрел легендарную щуку векующую в озорно...)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)"
      ],
      "metadata": {
        "id": "bjHTdbnnBYky"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('natasha.tsv', 'w', encoding='utf-8') as f:\n",
        "  f.write('form\\ttag\\n')\n",
        "  for i in doc.tokens:\n",
        "    f.write(f'{i.text}\\t{i.pos}\\n')"
      ],
      "metadata": {
        "id": "2tQWAdHPB9qC"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Аккуратность."
      ],
      "metadata": {
        "id": "TX6Sb44PDrEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция *change_tag* приводит все файлы к единому формату разметки."
      ],
      "metadata": {
        "id": "qdb_vaQgp6Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def change_tag(filename):\n",
        "  with open(filename) as f:\n",
        "    text = f.read()\n",
        "  text = re.sub('CCONJ', 'CONJ', text)\n",
        "  text = re.sub('SCONJ', 'CONJ', text)\n",
        "  text = re.sub('PRTS', 'VERB', text) # я приняла решение засчитывать все отглагольные вещи как глаголы: деепричастия, причастия, инфинитивы\n",
        "  text = re.sub('ADVB', 'ADV', text)\n",
        "  text = re.sub('ADJF', 'ADJ', text)\n",
        "  text = re.sub('ADJS', 'ADJ', text)\n",
        "  text = re.sub('NPRO', 'PRON', text)\n",
        "  text = re.sub('PRCL', 'PART', text)\n",
        "  text = re.sub('DET', 'ADJ', text)\n",
        "  text = re.sub('PREP', 'ADP', text)\n",
        "  text = re.sub('INFN', 'VERB', text)\n",
        "  text = re.sub('GRND', 'VERB', text)\n",
        "  text = re.sub('PRTF', 'VERB', text)\n",
        "  text = re.sub('COMP', 'ADJ', text)\n",
        "  with open(filename, 'w') as f:\n",
        "    f.write(text)"
      ],
      "metadata": {
        "id": "YAKEHJp7EPqW"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_files = ['golden.tsv', 'pymorphy.tsv', 'natasha.tsv', 'spacy.tsv']\n",
        "for i in list_files:\n",
        "  change_tag(i)"
      ],
      "metadata": {
        "id": "5er6e4tXdnT9"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def compare_lists(filename):\n",
        "  list1 = pd.read_csv('golden.tsv', delimiter='\\t')['tag'].values\n",
        "  list2 = pd.read_csv(filename, delimiter='\\t')['tag'].values\n",
        "  counter = 0\n",
        "\n",
        "  amount = np.array(list1) == np.array(list2)\n",
        "  for i in amount:\n",
        "      if i:\n",
        "        counter += 1\n",
        "  \n",
        "  accuracy = counter/len(list1)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "MDGFF6tZd5-C"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy for natasha: {compare_lists('natasha.tsv')}\", f\"Accuracy for spacy: {compare_lists('spacy.tsv')}\", \n",
        "      f\"Accuracy for pymorphy: {compare_lists('pymorphy.tsv')}\", sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgD_akVbkWlA",
        "outputId": "ad9d3588-e71e-4b7c-d0c0-ff41e9365112"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for natasha: 0.8897338403041825\n",
            "Accuracy for spacy: 0.935361216730038\n",
            "Accuracy for pymorphy: 0.8212927756653993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что касается омонимии, есть тэггеры, которые умеют справляться с ней, в том числе UDpipe. Поэтому неразличение омонимии тэггерами выше я считала за ошибку."
      ],
      "metadata": {
        "id": "P6DX2GgmqtFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. N-граммы"
      ],
      "metadata": {
        "id": "VCBNVcygrZ88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **не + прилагательное**, так как отрицательная частица *не* превращает все последующее высказывание в отрицание --> придает негативную окраску (из-за специфики текста - отзыв)\n",
        "2. **хорошо/плохо + прилагательное/причастие** типа *хорошо снятый*. Это улучшит анализ, так как поможет исключить позитивную идентификацию по слову *хорошо* в случаях - *хорошо, что я отдал билеты на этот фильм друзьям, ведь фильм ужасен*. (для *плохо* ситуация аналогичная + инвентарь подобных наречий можно расширить)\n",
        "3. **не + глагол**, по той же причине, что в п.1"
      ],
      "metadata": {
        "id": "bD36_p9nrgEu"
      }
    }
  ]
}